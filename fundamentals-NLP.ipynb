{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5374154a",
   "metadata": {},
   "source": [
    "# Bag of Words : NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6fe2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [\"I love music music\", \"I like studying computer science\", \"I feel happy today with music\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62867fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 2 stored elements and shape (1, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "vectors = vectorizer.fit_transform(train_X)\n",
    "\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6db6d",
   "metadata": {},
   "source": [
    "#### this is the simple representation of bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0175ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer' 'feel' 'happy' 'like' 'love' 'music' 'science' 'studying'\n",
      " 'today' 'with']\n",
      "[[0 0 0 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 1 0 0]\n",
      " [0 1 1 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(vectors.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fdc4a",
   "metadata": {},
   "source": [
    "# Words Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "106a13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959ccb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love music music', 'I like studying computer science', 'I feel happy today with music']\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29d774c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.86239982e-01  3.74150053e-02 -1.64199919e-02 -2.30407506e-01\n",
      "  1.11009769e-01  7.73264915e-02 -8.81674960e-02 -4.77592468e-01\n",
      " -2.95765281e-01  1.01987004e+00 -1.65709749e-01 -1.13386758e-01\n",
      "  1.23329505e-01 -7.30964765e-02 -1.96081400e-03  8.96607488e-02\n",
      "  4.39254977e-02  1.74748749e-01 -3.16554993e-01  2.49999985e-02\n",
      "  4.57475007e-01 -6.68449998e-02  2.13485003e-01 -7.50264972e-02\n",
      "  9.45267528e-02 -1.23472750e-01 -2.59433478e-01 -6.27825111e-02\n",
      "  6.47937477e-01  2.00645030e-02  2.22007245e-01  2.61448503e-01\n",
      " -4.74065006e-01 -8.74722525e-02 -5.37052527e-02 -6.75552487e-02\n",
      " -1.86225027e-03 -1.61408752e-01 -3.36000025e-02  1.82249844e-02\n",
      "  1.13129988e-01 -6.45565018e-02 -1.74637020e-01  2.56040007e-01\n",
      " -2.19412491e-01 -8.56050011e-03  5.27804971e-01  3.71862471e-01\n",
      " -3.07867765e-01  3.60955000e-01 -8.59449804e-03  2.29559004e-01\n",
      " -1.40350491e-01  2.11229742e-01 -1.43769994e-01  1.73105255e-01\n",
      "  2.09737271e-01  7.73975104e-02  1.40989006e-01 -6.05817497e-01\n",
      "  4.17292453e-02  2.03042254e-01 -4.70227480e-01  2.23543495e-01\n",
      " -5.03722578e-02 -7.04355016e-02 -1.15977496e-01 -8.36332515e-02\n",
      " -2.54904985e-01 -2.80284643e-01 -1.69945508e-01  4.37564999e-02\n",
      "  4.83699977e-01 -1.20684490e-01 -2.13328511e-01  5.68099953e-02\n",
      "  8.28474909e-02 -5.68000004e-02  1.28650486e-01  4.54699993e-02\n",
      "  2.21489996e-01  5.01362495e-02 -1.95946991e-02  2.51372486e-01\n",
      " -3.45744997e-01  2.29925007e-01  3.44057977e-01 -7.25840032e-01\n",
      " -9.33737457e-02 -6.11769736e-01 -1.08272001e-01 -1.38920501e-01\n",
      "  3.12824957e-02  3.98849994e-02  6.74025044e-02  2.36339979e-02\n",
      "  8.96600075e-03  1.00499362e-01 -5.41753769e-01  2.15799958e-02\n",
      "  2.35697508e-01 -3.68800014e-02 -1.19865753e-01  1.64714992e-01\n",
      "  3.43357503e-01  2.11642474e-01 -3.21897492e-02 -1.20095253e-01\n",
      "  1.31913513e-01 -1.08694002e-01  3.77812497e-02 -2.02948496e-01\n",
      " -8.35435018e-02 -1.76929504e-01 -1.35185257e-01  3.95233512e-01\n",
      "  6.88962489e-02  9.14549828e-02 -2.35367507e-01 -1.03879981e-02\n",
      "  2.30085012e-02  2.12952495e-01 -1.47102505e-01 -3.53719980e-01\n",
      "  5.53717576e-02  3.59350979e-01 -1.10210001e-01 -2.44337738e-01\n",
      "  1.24123752e-01  2.19999507e-01  1.21447496e-01  3.33607495e-02\n",
      " -1.36646986e-01 -3.00632417e-03  4.51063514e-01  1.25707000e-01\n",
      "  5.94715029e-02 -2.19077513e-01  2.47971490e-01  6.06250018e-03\n",
      " -3.27122498e+00 -1.39131486e-01 -7.91875124e-02  4.17207517e-02\n",
      " -1.59099996e-02 -2.48735026e-02  2.98874974e-02  2.78513759e-01\n",
      " -3.12423497e-01 -6.51292503e-01 -7.08124936e-02 -8.06339979e-02\n",
      "  1.83107495e-01  1.63245007e-01  1.03371754e-01 -3.66977528e-02\n",
      " -4.12889987e-01 -6.05002522e-01  2.32742250e-01  2.43850008e-01\n",
      " -4.22361568e-02  9.60240066e-02  2.93228507e-01  1.76973015e-01\n",
      "  5.62774986e-02  1.48719996e-01 -3.87265086e-02  1.63824737e-01\n",
      " -5.12799978e-01 -2.21900493e-01  3.41449976e-02 -1.49834603e-01\n",
      " -2.42752343e-01 -9.85972524e-01  1.72389001e-01  4.30482477e-02\n",
      " -1.59534991e-01  2.50784993e-01  1.40203997e-01 -2.34217495e-01\n",
      "  1.61442742e-01 -2.12087512e-01  1.52062476e-01  1.88077539e-02\n",
      "  4.90303487e-01  1.10182509e-01 -2.48835742e-01  5.46447486e-02\n",
      "  2.64574885e-02  8.59979987e-02  3.56230021e-01 -2.23221004e-01\n",
      " -6.11249954e-02 -2.01000109e-01  1.45474002e-01  5.68450987e-01\n",
      "  2.58252501e-01 -3.64802480e-01  4.02700007e-02  2.07537502e-01\n",
      " -1.48181006e-01 -2.76865005e-01  3.08047473e-01 -4.07701790e-01\n",
      "  1.46385506e-01 -5.24347484e-01  9.98805016e-02  3.30014765e-01\n",
      "  7.62974918e-02 -7.34850019e-02 -2.17920244e-01  4.19970006e-01\n",
      "  2.03949958e-02 -1.70532495e-01  2.50589490e-01  2.50932518e-02\n",
      "  1.61915004e-01  9.23775062e-02 -8.86049867e-02  9.79914963e-02\n",
      " -3.05127986e-02 -1.87642500e-02 -6.55080020e-01 -4.00302470e-01\n",
      "  3.27840984e-01 -1.15682501e-02  1.43623501e-01  6.23360053e-02\n",
      "  8.14139992e-02 -2.75065005e-02 -3.45172495e-01 -7.19980001e-02\n",
      " -3.11724991e-02  9.75774601e-03  2.71104515e-01 -4.03049961e-03\n",
      "  5.88175058e-02  1.15520004e-02 -3.03667754e-01  4.25990000e-02\n",
      " -1.61645502e-01  6.81129992e-02 -1.90441757e-01  1.06829375e-01\n",
      "  1.87435001e-02 -5.58359995e-02 -1.22642495e-01 -6.24762513e-02\n",
      " -1.93207502e-01  4.62975129e-02  2.63382513e-02  1.44400507e-01\n",
      "  3.46314251e-01  1.01336747e-01  1.58020519e-02 -2.33939737e-01\n",
      " -9.23789889e-02 -2.84867764e-01 -8.12446028e-02  2.60607470e-02\n",
      " -9.44635198e-02 -5.85075021e-02  2.89205015e-02 -1.15209997e-01\n",
      " -4.28224951e-02 -2.11230099e-01 -8.82113948e-02  5.04650027e-02\n",
      "  5.22605002e-01  5.03735006e-01  1.90872759e-01  1.77000463e-03\n",
      " -2.90952504e-01  1.03125125e-02  3.76666486e-01 -2.65027523e-01\n",
      " -3.74329984e-02 -2.57617503e-01  2.60240018e-01  2.16789752e-01\n",
      "  4.09848481e-01 -5.23552537e-01  1.06557995e-01  1.35354996e-02\n",
      "  1.00977503e-01  2.47759998e-01  4.45955038e-01 -2.06683010e-01\n",
      " -4.07422245e-01 -1.88569993e-01 -4.07234251e-01 -1.68892488e-01\n",
      "  1.50342524e-01  2.29234993e-01  1.76780254e-01  6.73917532e-02\n",
      " -9.34384912e-02 -3.70749980e-02 -1.95970252e-01  2.50429988e-01]\n"
     ]
    }
   ],
   "source": [
    "docs = [nlp(text) for text in train_X]\n",
    "print(docs[0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd6f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de8ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"Natural Language Processing (NLP) is a branch of artificial intelligence (AI) and computer science that enables computers to understand, interpret, and generate human language, both text and speech. By combining computational linguistics, statistical modeling, machine learning, and deep learning, NLP allows machines to process unstructured data, recognize sentiment, and automate communication.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1febd108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/lovanasaina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lovanasaina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b1e3f",
   "metadata": {},
   "source": [
    "## Tokenisation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6a7933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/home/lovanasaina/nltk_data/tokenizers/punkt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find('tokenizers/punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe7f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python utilisé : /usr/lib64/python3.13/os.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/lovanasaina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lovanasaina/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK path : ['/home/lovanasaina/nltk_data', '/usr/nltk_data', '/usr/share/nltk_data', '/usr/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/home/lovanasaina/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Python utilisé :\", os.__file__)\n",
    "\n",
    "# Télécharger explicitement dans ton home\n",
    "nltk.download('punkt', download_dir=os.path.expanduser('~/nltk_data'))\n",
    "nltk.download('punkt_tab', download_dir=os.path.expanduser('~/nltk_data'))\n",
    "\n",
    "nltk.data.path.append(os.path.expanduser('~/nltk_data'))\n",
    "print(\"NLTK path :\", nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4e36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f20fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing (NLP) is a branch of artificial intelligence (AI) and computer science that enables computers to understand, interpret, and generate human language, both text and speech.',\n",
       " 'By combining computational linguistics, statistical modeling, machine learning, and deep learning, NLP allows machines to process unstructured data, recognize sentiment, and automate communication.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6aca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) and computer science that enables computers to understand, interpret, and generate human language, both text and speech.\n",
      "\n",
      "By combining computational linguistics, statistical modeling, machine learning, and deep learning, NLP allows machines to process unstructured data, recognize sentiment, and automate communication.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sent:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f7d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'branch',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'language',\n",
       " ',',\n",
       " 'both',\n",
       " 'text',\n",
       " 'and',\n",
       " 'speech',\n",
       " '.',\n",
       " 'By',\n",
       " 'combining',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'statistical',\n",
       " 'modeling',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'allows',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'process',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " ',',\n",
       " 'recognize',\n",
       " 'sentiment',\n",
       " ',',\n",
       " 'and',\n",
       " 'automate',\n",
       " 'communication',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = word_tokenize(var)\n",
    "word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cde8cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c649d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6829e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_list = list(punctuation)+stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88e2e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_new = word_tokenize(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87b340a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "Language\n",
      "Processing\n",
      "NLP\n",
      "branch\n",
      "artificial\n",
      "intelligence\n",
      "AI\n",
      "computer\n",
      "science\n",
      "enables\n",
      "computers\n",
      "understand\n",
      "interpret\n",
      "generate\n",
      "human\n",
      "language\n",
      "text\n",
      "speech\n",
      "By\n",
      "combining\n",
      "computational\n",
      "linguistics\n",
      "statistical\n",
      "modeling\n",
      "machine\n",
      "learning\n",
      "deep\n",
      "learning\n",
      "NLP\n",
      "allows\n",
      "machines\n",
      "process\n",
      "unstructured\n",
      "data\n",
      "recognize\n",
      "sentiment\n",
      "automate\n",
      "communication\n"
     ]
    }
   ],
   "source": [
    "for i in var_new:\n",
    "    if i not in stop_word_list:\n",
    "        print(i)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f921e7",
   "metadata": {},
   "source": [
    "## Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34f5bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer, RegexpStemmer, PorterStemmer, SnowballStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LancasterStemmer()\n",
    "r = RegexpStemmer('ing') ## Ne modifie pas la racine \n",
    "p = PorterStemmer()\n",
    "s = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d561a2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chant'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"Chanting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51f82f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chant'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.stem(\"Chanting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59fb70d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chant'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem(\"Chanting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "103d8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07863ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "931615fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = WordNetLemmatizer()\n",
    "wl.lemmatize(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88810117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"I am the AI Engineer in m'i pich, is this a goode ojurneilll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1989142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.collections import BigramCollocationFinder, TrigramCollocationFinder, ngrams\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de1c30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word_tokenize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffa1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BigramCollocationFinder.from_words(w)\n",
    "t = TrigramCollocationFinder.from_words(w)\n",
    "n = ngrams(w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffbd17a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('I', 'am'): 1, ('am', 'the'): 1, ('the', 'AI'): 1, ('AI', 'Engineer'): 1, ('Engineer', 'in'): 1, ('in', 'm'): 1, ('m', \"'\"): 1, (\"'\", 'i'): 1, ('i', 'pich'): 1, ('pich', ','): 1, ...})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.ngram_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b66e12",
   "metadata": {},
   "source": [
    "## Count_Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f789e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"My name is Lova Nasaina\", \"i am computer science with the competence of AI Engineer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2606621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"name\":l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f2cf316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My name is Lova Nasaina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am computer science with the competence of A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name\n",
       "0                            My name is Lova Nasaina\n",
       "1  i am computer science with the competence of A..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ea2618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e453f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "new_data = cv.fit_transform(df[\"name\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d91014c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c219296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 7,\n",
       " 'name': 8,\n",
       " 'is': 5,\n",
       " 'lova': 6,\n",
       " 'nasaina': 9,\n",
       " 'am': 1,\n",
       " 'computer': 3,\n",
       " 'science': 11,\n",
       " 'with': 13,\n",
       " 'the': 12,\n",
       " 'competence': 2,\n",
       " 'of': 10,\n",
       " 'ai': 0,\n",
       " 'engineer': 4}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf970680",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9f7b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "letVar = \"I am the AI Engineer in m'i pich, is this a goode ojurneilll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6faeb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "144d140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lesk(word_tokenize(letVar), \"sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e735d369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the star that is the source of light and heat for the planets in the solar system'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd1c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
